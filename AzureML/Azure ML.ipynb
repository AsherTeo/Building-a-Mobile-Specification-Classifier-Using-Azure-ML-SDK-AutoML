{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d40c6f-52e5-45ae-b07c-d6b443071ca4",
   "metadata": {},
   "source": [
    "# Login Azure Cloud Plateform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f42baa-bbb6-43c4-bc9a-baafd45ca3e2",
   "metadata": {
    "gather": {
     "logged": 1728374775595
    }
   },
   "outputs": [],
   "source": [
    "################################### Azure ####################\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import dsl,Input, Output\n",
    "import mlflow\n",
    "import logging\n",
    "import webbrowser\n",
    "\n",
    "############################# Data Analysis & Others ############################\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "################################# Stastics & Machine Learning #####################\n",
    "\n",
    "from scipy.stats import skew, kstest\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ee2e51-e0dd-482f-97df-b0c4c0df16c3",
   "metadata": {
    "gather": {
     "logged": 1728374776071
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00481e37-e634-4cea-92c7-15420a8ea103",
   "metadata": {},
   "source": [
    "# Access the Resource Group and Work Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e984852-ccfc-45dc-9481-bf6ec51122e7",
   "metadata": {
    "gather": {
     "logged": 1728374776304
    }
   },
   "outputs": [],
   "source": [
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"xxxxxxxx-xxxx-40c6-xxxx-xxxxxxxxxxxx\",\n",
    "    resource_group_name=\"your_resource_group\",\n",
    "    workspace_name=\"your_workspace_name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bf2fd-e0ed-4186-ac17-b3947b997c2e",
   "metadata": {},
   "source": [
    "# Retrieve Url From Azure Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b990e875-2def-4219-87a2-355e693d2321",
   "metadata": {
    "gather": {
     "logged": 1728374776512
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "web_path = \"https://your_resource_group.blob.core.windows.net/datasets/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf480b3f-5faf-4839-8e6e-b45d832e056d",
   "metadata": {},
   "source": [
    "# Load the data to 'Data' in Azure ML Work Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584b69db-46ec-4afb-958c-daba8ef7ebc5",
   "metadata": {
    "gather": {
     "logged": 1728374776725
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileClassifications dataset was registered to workspace\n"
     ]
    }
   ],
   "source": [
    "data = Data(name=\"MobileClassifications\", path=web_path, type=AssetTypes.URI_FILE,\n",
    "            description=\"Dataset for mobile\", \n",
    "            tags={\"source_type\": \"web\", \"source\": \"AzureML examples blob\"},\n",
    "            version=\"1.0.3\")\n",
    "\n",
    "data = ml_client.data.create_or_update(data)\n",
    "print(f\"{data.name} dataset was registered to workspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e0707-7080-432a-ab22-c87c6d2f2d64",
   "metadata": {},
   "source": [
    "# Create Cluster Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1992280-b3bc-4c7d-b465-6dddad7be8f5",
   "metadata": {
    "gather": {
     "logged": 1728374776929
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named cpu-cluster123\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute = \"cpu-cluster123\"\n",
    "\n",
    "try:\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute)\n",
    "    print(f\"You already have a cluster named {cpu_compute}\")\n",
    "except Exception:\n",
    "    cpu_cluster = AmlCompute(name = \"cpu-cluster123\",\n",
    "                             type = \"amlcompute\",\n",
    "                             size = \"STANDARD_DS3_V2\",\n",
    "                             min_instances = 0,\n",
    "                             max_instances=4,\n",
    "                             idle_time_before_scale_down=120,\n",
    "                             tier = \"Dedicated\",\n",
    "                            )\n",
    "    cpu_cluster = ml_client.begin_create_or_update(cpu_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d469427e-b664-4d81-a48a-9f9c0a4655bb",
   "metadata": {},
   "source": [
    "# Create Custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fa0752-6341-44a9-90f5-db9f7a4fd9a3",
   "metadata": {
    "gather": {
     "logged": 1728374777138
    }
   },
   "outputs": [],
   "source": [
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9feac1-fe94-43a5-92bb-eda11bc6af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yaml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scikit-learn=0.24.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2  \n",
    "  - matplotlib=3.4.3  # Add this line for matplotlib\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - azureml-mlflow==1.42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b58127-d28f-4e0a-a644-6e08f447bdce",
   "metadata": {
    "gather": {
     "logged": 1728374777535
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name data_science_env is registered to workspace, the environment version is 0.1.1\n"
     ]
    }
   ],
   "source": [
    "custom_env_name = \"data_science_env\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"custom environment \",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.1.1\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76392aee-aed5-4535-a915-42bfc04c7e84",
   "metadata": {},
   "source": [
    "# Creating Piplines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266515c6-ff91-40cf-97a5-9e95f7e0f3d2",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0b1b84-260b-42b0-b425-4d6c56a184c7",
   "metadata": {
    "gather": {
     "logged": 1728374777743
    }
   },
   "outputs": [],
   "source": [
    "data_preprocessing_dir = \"./components/data_preprocessing\"\n",
    "\n",
    "os.makedirs(data_preprocessing_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ab5cdd-a254-47f8-ba4f-0156a80af83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/data_preprocessing/data_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {data_preprocessing_dir}/data_preprocessing.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--clean_data\", type=str, help=\"path to save cleaned data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    mlflow.start_run()\n",
    "\n",
    "    logging.info(\"Input data: %s\", args.data)\n",
    "    print(\"Input data:\", args.data)\n",
    "\n",
    "    df = pd.read_csv(args.data)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", df.shape[1])\n",
    "\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values_dict = missing_values[missing_values > 0].to_dict()\n",
    "    for feature, count in missing_values_dict.items():\n",
    "        mlflow.log_metric(f\"missing_values_{feature}\", count)\n",
    "\n",
    "\n",
    "    duplicate_values = df.duplicated().sum()\n",
    "    mlflow.log_metric(\"duplicate_values\", duplicate_values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    output_path = os.path.join(args.clean_data, \"cleaned_data.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    logging.info(\"Cleaned data saved to: %s\", output_path)\n",
    "\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebec76a2-492f-48f2-9c1a-e8d1dc3fc461",
   "metadata": {
    "gather": {
     "logged": 1728374778423
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component data_preprocessing with Version 2024-10-08-08-06-08-6306347 is registered\n"
     ]
    }
   ],
   "source": [
    "data_preprocessing_component = command(name=\"data_preprocessing\",\n",
    "                                        display_name=\"Data Preprocessing\",\n",
    "                                        description=\"Clean data\",\n",
    "                                        inputs={\"data\": Input(type=\"uri_folder\"),},\n",
    "                                        outputs=dict(\n",
    "                                            clean_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),),\n",
    "                                        code=data_preprocessing_dir,\n",
    "                                        command=\"\"\"python data_preprocessing.py \\\n",
    "                                                --data ${{inputs.data}} --clean_data ${{outputs.clean_data}} \"\"\",\n",
    "                                        environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\")\n",
    "\n",
    "data_preprocessing_component = ml_client.create_or_update(data_preprocessing_component.component)\n",
    "print(f\"Component {data_preprocessing_component.name} with Version {data_preprocessing_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066f515-f4d3-4596-8e2f-7d61b0b0c523",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77faecc9-673f-4bc8-a585-32618727888b",
   "metadata": {
    "gather": {
     "logged": 1728374778647
    }
   },
   "outputs": [],
   "source": [
    "feature_eng_dir = \"./components/feature_eng\"\n",
    "os.makedirs(feature_eng_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284a65c5-2c52-42bb-ae80-dc2a889b472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/feature_eng/feature_eng.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {feature_eng_dir}/feature_eng.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boxcox, skew\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "\n",
    "def select_first_file(path):\n",
    "    files = os.listdir(path)\n",
    "    if not files:\n",
    "        logging.error(\"No files found in the specified directory.\")\n",
    "        raise FileNotFoundError(\"No files found in the specified directory.\")\n",
    "    return os.path.join(path, files[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "  \n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--display_dir\", type=str, help=\"directory to save plots and results\")\n",
    "    parser.add_argument(\"--output_dir\", type=str, help=\"directory to save plots and results\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Start MLflow run\n",
    "    mlflow.start_run()\n",
    "\n",
    "    input_file = select_first_file(args.data)\n",
    "    logging.info(f\"Loading data from {input_file}\")\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    numerical = ['battery_power', 'clock_speed', 'fc',  'int_memory',  'mobile_wt',  \n",
    "                 'pc', 'px_height','px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
    "\n",
    "    cat = ['blue','dual_sim','four_g','m_dep','n_cores', 'three_g','touch_screen', 'wifi']\n",
    "\n",
    "    # Before Skewness\n",
    "    skewness_val = {col: skew(df[col]) for col in numerical}\n",
    "    skewness_before_df = pd.DataFrame(list(skewness_val.items()), columns=['Feature', 'Skewness']).sort_values(by='Skewness', ascending=False)\n",
    "\n",
    "    skewness_before_csv = os.path.join(args.display_dir, \"skew_before_df.csv\")\n",
    "    skewness_before_df.to_csv(skewness_before_csv, index=False)\n",
    "    logging.info(f\"Skewness Before saved to {skewness_before_csv}\")\n",
    "\n",
    "    mlflow.log_artifact(skewness_before_csv)\n",
    "\n",
    "    # After Skewness\n",
    "    for col in ['px_height', 'fc', 'sc_w', 'clock_speed']:\n",
    "        df[col] += 1  \n",
    "        transformed_data, _ = boxcox(df[col])\n",
    "        df[col] = transformed_data\n",
    "\n",
    "    skewness_val = {col: skew(df[col]) for col in numerical}\n",
    "    skewness_after_df = pd.DataFrame(list(skewness_val.items()), columns=['Feature', 'Skewness']).sort_values(by='Skewness', ascending=False)\n",
    "\n",
    "    skewness_after_csv = os.path.join(args.display_dir, \"skew_after_df.csv\")\n",
    "    skewness_after_df.to_csv(skewness_after_csv, index=False)\n",
    "    logging.info(f\"Skewness After saved to {skewness_after_csv}\")\n",
    "\n",
    "    mlflow.log_artifact(skewness_after_csv)\n",
    "\n",
    "    # ANOVA\n",
    "    selector = SelectKBest(f_classif, k=12)\n",
    "    X_anova = selector.fit_transform(df[numerical], df['price_range'])\n",
    "\n",
    "    anova_scores = selector.scores_\n",
    "    anova_p_values = selector.pvalues_\n",
    "\n",
    "    anova_df = pd.DataFrame({'Feature': numerical, 'P-Value': anova_p_values, 'Scores': anova_scores})\n",
    "    anova_df.sort_values(by='P-Value', ascending=True, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(anova_df['Feature'], anova_df['P-Value'], color='tab:red', alpha=0.6)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('P-Value')\n",
    "    plt.title('P-Values of Features from ANOVA')\n",
    "    plt.axhline(y=0.05, color='gray', linestyle='--', label='Significance Level (0.05)')\n",
    "    plt.legend()\n",
    "\n",
    "    anova_chart = os.path.join(args.display_dir, \"anova_p_values.png\")\n",
    "    plt.savefig(anova_chart)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(anova_chart)\n",
    "\n",
    "    # Save ANOVA DataFrame as a CSV\n",
    "    anova_csv = os.path.join(args.display_dir, \"anova_df.csv\")\n",
    "    anova_df.to_csv(anova_csv, index=False)\n",
    "    logging.info(f\"ANOVA DataFrame saved to {anova_csv}\")\n",
    "\n",
    "    mlflow.log_artifact(anova_csv)\n",
    "\n",
    "    # Chi Square\n",
    "    chi_scores = chi2(df[cat].astype(int), df['price_range'])\n",
    "    cat_df = pd.DataFrame({'Feature': cat, 'P-Value': chi_scores[1],})\n",
    "    cat_df.sort_values(by='P-Value', ascending=True, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.bar(cat_df['Feature'], cat_df['P-Value'], color='tab:blue', alpha=0.6)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('P-Value')\n",
    "    plt.title('P-Values of Features from Chi-Squared Test')\n",
    "    plt.axhline(y=0.05, color='gray', linestyle='--', label='Significance Level (0.05)')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    chi_square_chart = os.path.join(args.display_dir, \"chi_square_p_values.png\")\n",
    "    plt.savefig(chi_square_chart)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(chi_square_chart)\n",
    "\n",
    "    # Save Chi-Square DataFrame as a CSV\n",
    "    chi_square_csv = os.path.join(args.display_dir, \"chi_square_df.csv\")\n",
    "    cat_df.to_csv(chi_square_csv, index=False)\n",
    "    logging.info(f\"Chi-Square DataFrame saved to {chi_square_csv}\")\n",
    "\n",
    "    mlflow.log_artifact(chi_square_csv)\n",
    "\n",
    "    # Feature Selection\n",
    "    num_features = list(anova_df[anova_df['P-Value'] <= 0.05]['Feature'])\n",
    "    cat_features = list(cat_df[cat_df['P-Value'] <= 0.05]['Feature'])\n",
    "\n",
    "    #df[cat_features] = df[cat_features].astype(str)\n",
    "\n",
    "    output_data = pd.concat([df[num_features].add_suffix('_num'), \n",
    "                          df[cat_features].add_suffix('_cat'), \n",
    "                          df['price_range']], \n",
    "                         axis=1)\n",
    "\n",
    "    output_data_csv = os.path.join(args.output_dir, \"output_data.csv\")\n",
    "    output_data.to_csv(output_data_csv, index=False)\n",
    "    \n",
    "    logging.info(f\"Output data saved to {output_data_csv}\")\n",
    "    mlflow.log_artifact(output_data_csv)\n",
    "\n",
    " \n",
    "\n",
    "    mlflow.end_run()   \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f39df2-9055-4865-991c-519fea0866e2",
   "metadata": {
    "gather": {
     "logged": 1728374779037
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component feature_eng with Version 2024-10-08-08-06-13-9334982 is registered\n"
     ]
    }
   ],
   "source": [
    "feature_eng_component = command(\n",
    "                        name=\"feature_eng\",\n",
    "                        display_name=\"Feature Engineering\",\n",
    "                        description=\"Feature engineering component for ANOVA analysis\",\n",
    "                        inputs={\n",
    "                            \"data\": Input(type=\"uri_folder\"),   \n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            output_dir=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                            display_dir=Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
    "                        ),\n",
    "                        code=feature_eng_dir,\n",
    "                        command=\"\"\"python feature_eng.py \\\n",
    "                                    --data ${{inputs.data}} \\\n",
    "                                    --output_dir ${{outputs.output_dir}}  \\\n",
    "                                    --display_dir ${{outputs.display_dir}} \n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "feature_eng_component= ml_client.create_or_update(feature_eng_component.component)\n",
    "print(f\"Component {feature_eng_component.name} with Version {feature_eng_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ee2e9-41c2-4f01-9fd5-56071aa12ee8",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a6c6a3-e3ae-425c-a845-d607d2eec5d9",
   "metadata": {
    "gather": {
     "logged": 1728374779261
    }
   },
   "outputs": [],
   "source": [
    "train_src_dir = \"./components/train\"\n",
    "os.makedirs(train_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "000eba0d-29b8-4669-8cf6-ee758e1078e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {train_src_dir}/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import mltable\n",
    "\n",
    "def select_first_file(path):\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "    \n",
    "def evaluate_model(scaler, X_train, y_train, num_features, cat_features, model, cv):\n",
    "    transformer = ColumnTransformer(transformers=[('num', scaler, num_features), ('cat', OneHotEncoder(), cat_features)])\n",
    "    pipeline = Pipeline([('preprocessor', transformer), ('model', model)])\n",
    "\n",
    "    ave_precision = np.mean(cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='precision_weighted'))\n",
    "    ave_recall = np.mean(cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='recall_weighted'))\n",
    "    ave_f1 = np.mean(cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1_weighted'))\n",
    "    ave_accuracy = np.mean(cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy'))\n",
    "    \n",
    "    return ave_precision, ave_recall, ave_f1, ave_accuracy\n",
    "\n",
    "# Start Logging\n",
    "mlflow.start_run()\n",
    "\n",
    "# Enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for training the model.\"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--cv\", type=int, default = 5, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--top_models\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--train_data\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--test_data\", type=str, help=\"Path to train data\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    num_features,cat_features = [], []\n",
    "    # Load and prepare training data\n",
    "    df = pd.read_csv(select_first_file(args.data))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_num'):\n",
    "            num_features.append(col)\n",
    "        if col.endswith('_cat'):\n",
    "            cat_features.append(col)\n",
    "            \n",
    "    X = df.drop(columns = \"price_range\")\n",
    "    y = df['price_range']\n",
    "\n",
    "    print(f\"Training with data of shape {X.shape}\")\n",
    "\n",
    "    random_state=42\n",
    "\n",
    "    scalers = [MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "    \n",
    "    svc_model = SVC(random_state = random_state) \n",
    "    gbc_model = GradientBoostingClassifier(random_state = random_state)\n",
    "    rf_model = RandomForestClassifier(random_state = random_state)\n",
    "    knn_model = KNeighborsClassifier()\n",
    "    xgb_model = XGBClassifier(random_state = random_state)\n",
    "    lgb_model = LGBMClassifier(random_state = random_state, verbose= -1)\n",
    "    cat_model = CatBoostClassifier(random_state = random_state, logging_level='Silent')\n",
    "    \n",
    "    models = ('SVM', svc_model), ('GB', gbc_model), ('RF', rf_model), ('KNN', knn_model), ('XGB', xgb_model), ('LGB', lgb_model), ('CAT', cat_model)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for scaler in scalers:\n",
    "        for model_name, model in models:\n",
    "            ave_precision, ave_recall, ave_f1, ave_acc = evaluate_model(scaler, X_train, y_train, num_features, cat_features, model, args.cv)\n",
    "    \n",
    "            results.append({\n",
    "                'Scaler': scaler,\n",
    "                'Model': model_name,\n",
    "                'Precision': ave_precision,\n",
    "                'Recall': ave_recall,\n",
    "                'F1 Score': ave_f1,\n",
    "                'Accuracy': ave_acc\n",
    "                \n",
    "            })\n",
    "\n",
    "    df_model = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False).reset_index(drop=True)\n",
    "    print(df_model)\n",
    "\n",
    "    df_model_sorted = df_model.sort_values(by='F1 Score', ascending=False)\n",
    "    top_unique_models = df_model_sorted.drop_duplicates(subset='Model')\n",
    "    top_models_df = top_unique_models.head(3)\n",
    "\n",
    "    print(f\"Top 3 models:\\n{top_models_df}\")\n",
    "\n",
    "    top_3_csv = os.path.join(args.top_models, \"top_3_models.csv\")\n",
    "    top_models_df.to_csv(top_3_csv, index=False)\n",
    "\n",
    "    train_df = pd.concat([X_train.reset_index(drop=True),y_train.reset_index(drop=True)], axis = 1)\n",
    "    train_data_csv = os.path.join(args.train_data, \"train_data_data.csv\")\n",
    "    train_df.to_csv(train_data_csv, index=False)\n",
    "    \n",
    "    test_df = pd.concat([X_test.reset_index(drop=True),y_test.reset_index(drop=True)], axis = 1)\n",
    "    test_data_csv = os.path.join(args.test_data, \"test_data_data.csv\")\n",
    "    test_df.to_csv(test_data_csv, index=False)\n",
    "\n",
    "    mlflow.log_artifact(top_3_csv)         \n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc6f0d22-6708-4385-a4b8-2c0243dadc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/train_env.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/train_env.yaml\n",
    "\n",
    "name: sklearn-1.5\n",
    "channels:\n",
    "- conda-forge\n",
    "- anaconda\n",
    "dependencies:\n",
    "- python=3.10\n",
    "- pip=21.3.1\n",
    "- pandas~=1.5.3\n",
    "- scipy~=1.10.0\n",
    "- numpy~=1.22.0\n",
    "- pip:\n",
    "  - scikit-learn-intelex==2024.7.0\n",
    "  - azureml-core==1.57.0.post1\n",
    "  - azureml-defaults==1.57.0.post1\n",
    "  - azureml-mlflow==1.57.0.post1\n",
    "  - azureml-telemetry==1.57.0\n",
    "  - scikit-learn~=1.5.0\n",
    "  - joblib~=1.2.0\n",
    "  - xgboost~=1.7.0\n",
    "  - catboost~=1.2.0  \n",
    "  - lightgbm~=3.3.5  \n",
    "  - optuna~=3.2.0\n",
    "  - azure-ai-ml==1.9.0\n",
    "  - mltable\n",
    "  # azureml-automl-common-tools packages\n",
    "  - py-spy==0.3.12\n",
    "  - debugpy~=1.6.3\n",
    "  - ipykernel~=6.0\n",
    "  - tensorboard\n",
    "  - psutil~=5.8.0\n",
    "  - matplotlib~=3.5.0\n",
    "  - tqdm~=4.66.3\n",
    "  - py-cpuinfo==5.0.0\n",
    "  - torch-tb-profiler~=0.4.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cee052-baf8-4ce6-8da4-c984fbdc5450",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728374779843
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name train_env is registered to workspace, the environment version is 0.1.6\n"
     ]
    }
   ],
   "source": [
    "custom_env_name = \"train_env\"\n",
    "\n",
    "pipeline_job_env_train = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"custom environment \",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"train_env.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.1.6\",\n",
    ")\n",
    "pipeline_job_env_train = ml_client.environments.create_or_update(pipeline_job_env_train)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env_train.name} is registered to workspace, the environment version is {pipeline_job_env_train.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "318c4a9e-109b-4491-ab97-565e736f4d17",
   "metadata": {
    "gather": {
     "logged": 1728374780546
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component train_model with Version 2024-10-08-08-06-16-9483462 is registered\n"
     ]
    }
   ],
   "source": [
    "train_component = command(\n",
    "                        name=\"train_model\",\n",
    "                        display_name=\"Train Model\",\n",
    "                        description=\"\",\n",
    "                        inputs={\n",
    "                            \"data\": Input(type=\"uri_folder\"), \"cv\":Input(type=\"number\") \n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            top_models=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                            train_data = Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                            test_data = Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                    \n",
    "                        ),\n",
    "                        code=train_src_dir,\n",
    "                        command=\"\"\"python train.py \\\n",
    "                                    --data ${{inputs.data}} \\\n",
    "                                    --cv ${{inputs.cv}}  \\\n",
    "                                    --top_models ${{outputs.top_models}}  \\\n",
    "                                    --train_data ${{outputs.train_data}} \\\n",
    "                                    --test_data ${{outputs.test_data}}\n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env_train.name}:{pipeline_job_env_train.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "train_component= ml_client.create_or_update(train_component.component)\n",
    "print(f\"Component {train_component.name} with Version {train_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd36a9-2d6b-4e91-928f-b93449705a0b",
   "metadata": {},
   "source": [
    "## Model FineTuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2608845-6bff-45c4-b071-c415de333219",
   "metadata": {
    "gather": {
     "logged": 1728374780772
    }
   },
   "outputs": [],
   "source": [
    "optuna_dir = \"./components/finetune\"\n",
    "os.makedirs(optuna_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c86185-de40-4a94-bac1-86500a7403d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/finetune/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {optuna_dir}/utils.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import optuna\n",
    "\n",
    "def select_first_file(path):\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[0])\n",
    "    \n",
    "def load_data(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    num_features = [col for col in df.columns if col.endswith('_num')]\n",
    "    cat_features = [col for col in df.columns if col.endswith('_cat')]\n",
    "    \n",
    "    X_train = df.drop(columns=\"price_range\")\n",
    "    y_train = df['price_range']\n",
    "    return X_train, y_train, num_features, cat_features\n",
    "\n",
    "def is_scaler(scaler):\n",
    "    if scaler == 'RobustScaler()':\n",
    "        scalers = RobustScaler()\n",
    "\n",
    "    elif scaler == 'StandardScaler()':\n",
    "        scalers = StandardScaler()\n",
    "\n",
    "    elif scaler == 'MinMaxScaler()':\n",
    "        scalers = MinMaxScaler()\n",
    "    else:\n",
    "        scalers = None\n",
    "        print(f\"Scaler '{scaler}' is not recognized. Returning None.\")\n",
    "    return scalers\n",
    "\n",
    "def objective(trial, scaler, model_type, X_train, y_train, num_features, cat_features, cv):\n",
    "\n",
    "\n",
    "    if model_type == 'CAT':\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 7)\n",
    "        n_estimators = trial.suggest_int('n_estimators', 2000, 3000)\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            logging_level='Silent',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif model_type == 'SVM':\n",
    "        C = trial.suggest_int('C', 1, 20)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "        degree = trial.suggest_int('degree', 1, 10)\n",
    "\n",
    "        model = SVC(C=C, kernel=kernel, degree=degree, random_state=42)\n",
    "\n",
    "    elif model_type == 'LGB':\n",
    "        num_leaves = trial.suggest_int('num_leaves', 150, 500)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.05, 0.08)\n",
    "        min_child_samples = trial.suggest_int('min_child_samples', 25, 50)\n",
    "        n_estimators = trial.suggest_int('n_estimators', 1000, 5000)\n",
    "\n",
    "        model = LGBMClassifier(\n",
    "            num_leaves=num_leaves, \n",
    "            learning_rate=learning_rate, \n",
    "            min_child_samples=min_child_samples,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', is_scaler(scaler), num_features), \n",
    "            ('cat', OneHotEncoder(), cat_features)  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    precision_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='precision_weighted')\n",
    "    recall_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='recall_weighted')\n",
    "    f1_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1_weighted')\n",
    "    \n",
    "    mlflow.log_metric('average_accuracy', np.mean(accuracy_scores))\n",
    "    mlflow.log_metric('average_precision', np.mean(precision_scores))\n",
    "    mlflow.log_metric('average_recall', np.mean(recall_scores))\n",
    "    mlflow.log_metric('average_f1_score', np.mean(f1_scores))\n",
    "\n",
    "    return np.mean(f1_scores) , np.mean(accuracy_scores), np.mean(precision_scores), np.mean(recall_scores)\n",
    "\n",
    "def train_model(model_type, scaler, X_train, y_train,num_features,  cat_features, best_trial):\n",
    "    best_params = best_trial.params\n",
    "    if model_type == 'CAT':\n",
    "        model = CatBoostClassifier(**best_params)\n",
    "    \n",
    "    elif model_type == 'SVM':\n",
    "        model = SVC(**best_params)\n",
    "\n",
    "    elif model_type == 'LGB':\n",
    "        model = LGBMClassifier(**best_params)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "        \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', is_scaler(scaler), num_features), \n",
    "            ('cat', OneHotEncoder(), cat_features)  \n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84ba1d5-bd77-4413-aaa2-30becdba7f1c",
   "metadata": {},
   "source": [
    "## FineTune Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "effd68f1-9f91-48e7-8050-ae59b14008e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/finetune/finetune_model1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {optuna_dir}/finetune_model1.py\n",
    "from utils import load_data, select_first_file, objective, train_model\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import optuna\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_data\", type=str, required=True, help=\"Path to train data directory\")\n",
    "    parser.add_argument(\"--top_model_1\", type=str, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--n_trials\", type=int, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--model_1\", type=str, help=\"Type of model to optimize\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_data = select_first_file(args.train_data)\n",
    "    X_train, y_train, num_features, cat_features = load_data(train_data)\n",
    "\n",
    "    top_models_df = pd.read_csv(select_first_file(args.top_model_1))\n",
    "    top_model = top_models_df.iloc[0]\n",
    "    scaler = top_model['Scaler']\n",
    "    model_type = top_model['Model']\n",
    "   \n",
    "    study = optuna.create_study(directions=['maximize', 'maximize', 'maximize', 'maximize'])\n",
    "    study.optimize(lambda trial: objective(trial, scaler, model_type, X_train, y_train, num_features, cat_features, 5), n_trials=args.n_trials)\n",
    "\n",
    "    best_trial = study.best_trials[0]\n",
    "\n",
    "    best_accuracy, best_precision, best_recall, best_f1_score = best_trial.values[0], best_trial.values[1], best_trial.values[2], best_trial.values[3]\n",
    "    \n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "    print(\"Best Precision:\", best_precision)\n",
    "    print(\"Best Recall:\", best_recall)\n",
    "    print(\"Best F1:\", best_f1_score)\n",
    "    print(\"Best trial parameters:\", best_trial.params)\n",
    "\n",
    "    mlflow.log_metric('best_f1_score', best_f1_score)\n",
    "\n",
    "    pipeline = train_model(model_type, scaler, X_train, y_train,num_features,  cat_features, best_trial)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [model_type],\n",
    "        'Best_F1_Score': [best_f1_score],\n",
    "        'Best_Accuracy': [best_accuracy],\n",
    "        'Best_Precision': [best_precision],\n",
    "        'Best_Recall': [best_recall],\n",
    "        'Best Parameter': [best_trial.params],\n",
    "        \n",
    "    })\n",
    "\n",
    "\n",
    "    results_path = os.path.join(args.model_1, \"Model_best_1.csv\")\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    mlflow.log_artifact(results_path) \n",
    "\n",
    "    model_saved_path = os.path.join(args.model_1, \"trained_model.pkl\")  \n",
    "    dump(pipeline, model_saved_path)  \n",
    "    mlflow.log_artifact(model_saved_path)\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f442075d-fb32-45e0-b312-34a3836f48b1",
   "metadata": {
    "gather": {
     "logged": 1728374781695
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component finetune_model1 with Version 2024-10-08-08-06-19-5382955 is registered\n"
     ]
    }
   ],
   "source": [
    "finetune_model1_component = command(\n",
    "                        name=\"finetune_model1\",\n",
    "                        display_name=\"Finetune Model 1\",\n",
    "                        description=\"\",\n",
    "                        inputs={\n",
    "                            'top_model_1': Input(type=\"uri_folder\"),\n",
    "                            \"train_data\": Input(type=\"uri_folder\"), 'n_trials':Input(type=\"number\")\n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            model_1 =Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                    \n",
    "                        ),\n",
    "                        code=optuna_dir,\n",
    "                        command=\"\"\"python finetune_model1.py \\\n",
    "                                    --train_data ${{inputs.train_data}} \\\n",
    "                                    --n_trials ${{inputs.n_trials}} \\\n",
    "                                    --top_model_1 ${{inputs.top_model_1}} \\\n",
    "                                    --model_1 ${{outputs.model_1}} \n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env_train.name}:{pipeline_job_env_train.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "finetune_model1_component= ml_client.create_or_update(finetune_model1_component.component)\n",
    "print(f\"Component {finetune_model1_component.name} with Version {finetune_model1_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631ae62-b5c8-4914-b118-c633cd77f20e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# FineTune Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47d30720-d1c3-42fe-9a63-21739052696d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/finetune/finetune_model2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {optuna_dir}/finetune_model2.py\n",
    "from utils import load_data, select_first_file, objective, train_model\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import optuna\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_data\", type=str, required=True, help=\"Path to train data directory\")\n",
    "    parser.add_argument(\"--top_model_2\", type=str, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--n_trials\", type=int, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--model_2\", type=str, help=\"Type of model to optimize\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_data = select_first_file(args.train_data)\n",
    "    X_train, y_train, num_features, cat_features = load_data(train_data)\n",
    "\n",
    "    top_models_df = pd.read_csv(select_first_file(args.top_model_2))\n",
    "    top_model = top_models_df.iloc[1]\n",
    "    scaler = top_model['Scaler']\n",
    "    model_type = top_model['Model']\n",
    "   \n",
    "    study = optuna.create_study(directions=['maximize', 'maximize', 'maximize', 'maximize'])\n",
    "    study.optimize(lambda trial: objective(trial, scaler, model_type, X_train, y_train, num_features, cat_features, 5), n_trials=args.n_trials)\n",
    "    \n",
    "    best_trial = study.best_trials[0]\n",
    "\n",
    "    best_accuracy, best_precision, best_recall, best_f1_score = best_trial.values[0], best_trial.values[1], best_trial.values[2], best_trial.values[3]\n",
    "    \n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "    print(\"Best Precision:\", best_precision)\n",
    "    print(\"Best Recall:\", best_recall)\n",
    "    print(\"Best F1:\", best_f1_score)\n",
    "    print(\"Best trial parameters:\", best_trial.params)\n",
    "\n",
    "    mlflow.log_metric('best_f1_score', best_f1_score)\n",
    "\n",
    "    pipeline = train_model(model_type, scaler, X_train, y_train,num_features,  cat_features, best_trial)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [model_type],\n",
    "        'Best_F1_Score': [best_f1_score],\n",
    "        'Best_Accuracy': [best_accuracy],\n",
    "        'Best_Precision': [best_precision],\n",
    "        'Best_Recall': [best_recall],\n",
    "        'Best Parameter': [best_trial.params],\n",
    "        \n",
    "    })\n",
    "\n",
    "    results_path = os.path.join(args.model_2, \"Model_best_2.csv\")\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    mlflow.log_artifact(results_path) \n",
    "\n",
    "    model_saved_path = os.path.join(args.model_2, \"trained_mode2.pkl\")  \n",
    "    dump(pipeline, model_saved_path)  \n",
    "    mlflow.log_artifact(model_saved_path)\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f78f9c9a-181d-474e-8646-526815cd50ef",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728374782714
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component finetune_model2 with Version 2024-10-08-08-06-22-2153979 is registered\n"
     ]
    }
   ],
   "source": [
    "finetune_model2_component = command(\n",
    "                        name=\"finetune_model2\",\n",
    "                        display_name=\"Finetune Model 2\",\n",
    "                        description=\"\",\n",
    "                        inputs={\n",
    "                            'top_model_2': Input(type=\"uri_folder\"),\n",
    "                            \"train_data\": Input(type=\"uri_folder\"), 'n_trials':Input(type=\"number\")\n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            model_2 =Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                    \n",
    "                        ),\n",
    "                        code=optuna_dir,\n",
    "                        command=\"\"\"python finetune_model2.py \\\n",
    "                                    --train_data ${{inputs.train_data}} \\\n",
    "                                    --n_trials ${{inputs.n_trials}} \\\n",
    "                                    --top_model_2 ${{inputs.top_model_2}} \\\n",
    "                                    --model_2 ${{outputs.model_2}} \n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env_train.name}:{pipeline_job_env_train.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "finetune_model2_component= ml_client.create_or_update(finetune_model2_component.component)\n",
    "print(f\"Component {finetune_model2_component.name} with Version {finetune_model2_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64e791-eb85-42be-8e6b-3603e9bddb62",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# FineTune Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f19d6cd-759b-4e63-a65b-de8dd0da5ba9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/finetune/finetune_model3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {optuna_dir}/finetune_model3.py\n",
    "from utils import load_data, select_first_file, objective, train_model\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import optuna\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_data\", type=str, required=True, help=\"Path to train data directory\")\n",
    "    parser.add_argument(\"--top_model_3\", type=str, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--n_trials\", type=int, help=\"Type of model to optimize\")\n",
    "    parser.add_argument(\"--model_3\", type=str, help=\"Type of model to optimize\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_data = select_first_file(args.train_data)\n",
    "    X_train, y_train, num_features, cat_features = load_data(train_data)\n",
    "\n",
    "    top_models_df = pd.read_csv(select_first_file(args.top_model_3))\n",
    "    top_model = top_models_df.iloc[2]\n",
    "    scaler = top_model['Scaler']\n",
    "    model_type = top_model['Model']\n",
    "   \n",
    "    study = optuna.create_study(directions=['maximize', 'maximize', 'maximize', 'maximize'])\n",
    "    study.optimize(lambda trial: objective(trial, scaler, model_type, X_train, y_train, num_features, cat_features, 5), n_trials=args.n_trials)\n",
    "    \n",
    "\n",
    "    best_trial = study.best_trials[0]\n",
    "\n",
    "    best_accuracy, best_precision, best_recall, best_f1_score = best_trial.values[0], best_trial.values[1], best_trial.values[2], best_trial.values[3]\n",
    "    \n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "    print(\"Best Precision:\", best_precision)\n",
    "    print(\"Best Recall:\", best_recall)\n",
    "    print(\"Best F1:\", best_f1_score)\n",
    "    print(\"Best trial parameters:\", best_trial.params)\n",
    "\n",
    "    mlflow.log_metric('best_f1_score', best_f1_score)\n",
    "\n",
    "\n",
    "    pipeline = train_model(model_type, scaler, X_train, y_train,num_features,  cat_features, best_trial)\n",
    "    pipeline.fit(X_train, y_train)\n",
    " \n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [model_type],\n",
    "        'Best_F1_Score': [best_f1_score],\n",
    "        'Best_Accuracy': [best_accuracy],\n",
    "        'Best_Precision': [best_precision],\n",
    "        'Best_Recall': [best_recall],\n",
    "        'Best Parameter': [best_trial.params],\n",
    "        \n",
    "    })\n",
    "\n",
    "    results_path = os.path.join(args.model_3, \"Model_best_3.csv\")\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    mlflow.log_artifact(results_path) \n",
    "\n",
    "    model_saved_path = os.path.join(args.model_3, \"trained_mode3.pkl\")  \n",
    "    dump(pipeline, model_saved_path)  \n",
    "    mlflow.log_artifact(model_saved_path)\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48e07e0-6f9d-479a-9446-161b17ddd175",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728374785532
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component finetune_model2 with Version 2024-10-08-08-06-25-2930373 is registered\n"
     ]
    }
   ],
   "source": [
    "finetune_model3_component = command(\n",
    "                        name=\"finetune_model2\",\n",
    "                        display_name=\"Finetune Model 3\",\n",
    "                        description=\"\",\n",
    "                        inputs={\n",
    "                            'top_model_3': Input(type=\"uri_folder\"),\n",
    "                            \"train_data\": Input(type=\"uri_folder\"), 'n_trials':Input(type=\"number\")\n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            model_3  =Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                    \n",
    "                        ),\n",
    "                        code=optuna_dir,\n",
    "                        command=\"\"\"python finetune_model3.py \\\n",
    "                                    --train_data ${{inputs.train_data}} \\\n",
    "                                    --n_trials ${{inputs.n_trials}} \\\n",
    "                                    --top_model_3 ${{inputs.top_model_3}} \\\n",
    "                                    --model_3 ${{outputs.model_3}} \n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env_train.name}:{pipeline_job_env_train.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "finetune_model3_component= ml_client.create_or_update(finetune_model3_component.component)\n",
    "print(f\"Component {finetune_model3_component.name} with Version {finetune_model3_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c938446-d1a2-4218-b28d-68bbe3095743",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96b20778-a338-412f-91db-d6f32640e326",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/finetune/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {optuna_dir}/evaluate.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "\n",
    "def select_first_file(path, num):\n",
    "    files = os.listdir(path)\n",
    "    return os.path.join(path, files[num])\n",
    "\n",
    "def score(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return precision,recall,f1\n",
    "    \n",
    "    \n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for training the model.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--test_data\", type=str, help=\"Path to test data\")\n",
    "    parser.add_argument(\"--model_1\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--model_2\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--model_3\", type=str, help=\"Path to train data\")\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"Model name\")\n",
    "    parser.add_argument(\"--best_model\", type=str, help=\"path to model file\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "\n",
    "    model1 = load(select_first_file(args.model_1,1))\n",
    "    model2 = load(select_first_file(args.model_2,1))\n",
    "    model3 = load(select_first_file(args.model_3,1))\n",
    "\n",
    "    test_df = pd.read_csv(select_first_file(args.test_data,0))\n",
    "\n",
    "    X_test = test_df.drop(columns=\"price_range\")\n",
    "    y_test = test_df['price_range']\n",
    "\n",
    "    precision_1,recall_1,f1_1 = score(model1, X_test, y_test)\n",
    "    precision_2,recall_2,f1_2 = score(model2, X_test, y_test)\n",
    "    precision_3,recall_3,f1_3 = score(model3, X_test, y_test)\n",
    "    \n",
    "    scores_df = pd.DataFrame({'model': ['model1', 'model2', 'model3'],\n",
    "                                'precision': [precision_1, precision_2, precision_3],\n",
    "                                'recall': [recall_1, recall_2, recall_3],\n",
    "                                'f1': [f1_1, f1_2, f1_3]})\n",
    "\n",
    "    sorted_scores_df = scores_df.sort_values(by='f1', ascending=False)\n",
    "\n",
    "    Best_model = sorted_scores_df.iloc[0]['model']\n",
    "    best_f1score = sorted_scores_df.iloc[0]['f1']\n",
    "\n",
    "    if Best_model == 'model1':\n",
    "        Best_model = model1\n",
    "    elif Best_model == 'model2':\n",
    "        Best_model = model2\n",
    "    else:\n",
    "        Best_model = model3\n",
    "\n",
    "    results_path = os.path.join(args.best_model, \"test_result.csv\")\n",
    "    sorted_scores_df.to_csv(results_path, index=False)\n",
    "    mlflow.log_artifact(results_path) \n",
    "\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "        \n",
    "    with mlflow.start_run(run_name=args.registered_model_name):\n",
    "        print(\"Registering the model via MLFlow\")\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=Best_model,\n",
    "            registered_model_name=args.registered_model_name,\n",
    "            artifact_path='best_model',  \n",
    "        )\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3b8ad4d-6d42-46af-8492-fbd987740ba2",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728374787692
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component evaluation with Version 2024-10-08-08-06-28-2126087 is registered\n"
     ]
    }
   ],
   "source": [
    "evaluate_component = command(\n",
    "                        name=\"evaluation\",\n",
    "                        display_name=\"Evaluation\",\n",
    "                        description=\"\",\n",
    "                        inputs={\n",
    "                            'model_1': Input(type=\"uri_folder\"),\n",
    "                            \"model_2\": Input(type=\"uri_folder\"), 'model_3':Input(type=\"uri_folder\"),\n",
    "                            'test_data': Input(type=\"uri_folder\"), 'registered_model_name':Input(type=\"string\")\n",
    "                        },\n",
    "                        outputs=dict(\n",
    "                            best_model  =Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                    \n",
    "                        ),\n",
    "                        code=optuna_dir,\n",
    "                        command=\"\"\"python evaluate.py \\\n",
    "                                    --model_1 ${{inputs.model_1}} \\\n",
    "                                    --model_2 ${{inputs.model_2}} \\\n",
    "                                    --model_3 ${{inputs.model_3}} \\\n",
    "                                    --test_data ${{inputs.test_data}} \\\n",
    "                                    --registered_model_name ${{inputs.registered_model_name}} \\\n",
    "                                    --best_model ${{outputs.best_model}}\n",
    "    \n",
    "                                \"\"\",\n",
    "                        environment=f\"{pipeline_job_env_train.name}:{pipeline_job_env_train.version}\",\n",
    "                    )\n",
    "\n",
    "# Register the component\n",
    "evaluate_component= ml_client.create_or_update(evaluate_component.component)\n",
    "print(f\"Component {evaluate_component.name} with Version {evaluate_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81868d2c-5742-4a86-ba3b-6600092b4db5",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Connect Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1551a147-2c36-42f8-aafa-c033d3563803",
   "metadata": {
    "gather": {
     "logged": 1728374791441
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    compute=\"serverless\",\n",
    "    description=\"train pipeline\",\n",
    ")\n",
    "def train_pipeline(pipeline_job_data_input, pipeline_job_cv, \n",
    "                   pipeline_job_n_trials,pipeline_job_registered_model_name): \n",
    "\n",
    "    data_preprocessing_job = data_preprocessing_component(\n",
    "        data = pipeline_job_data_input\n",
    "    )\n",
    "    feature_eng_job = feature_eng_component(\n",
    "        data = data_preprocessing_job.outputs.clean_data\n",
    "    )   \n",
    "    train_job = train_component(\n",
    "        data = feature_eng_job.outputs.output_dir,\n",
    "        cv = pipeline_job_cv\n",
    "         \n",
    "    ) \n",
    "\n",
    "    finetune_model1_job = finetune_model1_component(\n",
    "            train_data = train_job.outputs.train_data,\n",
    "            n_trials = pipeline_job_n_trials,\n",
    "            top_model_1 = train_job.outputs.top_models\n",
    "    )\n",
    "    finetune_model2_job = finetune_model2_component(\n",
    "            train_data = train_job.outputs.train_data, \n",
    "            n_trials = pipeline_job_n_trials,\n",
    "            top_model_2 = train_job.outputs.top_models\n",
    "    )\n",
    "\n",
    "    finetune_model3_job = finetune_model3_component(\n",
    "        train_data = train_job.outputs.train_data,\n",
    "        n_trials = pipeline_job_n_trials,\n",
    "        top_model_3 = train_job.outputs.top_models\n",
    "    ) \n",
    "\n",
    "    evaluate_job = evaluate_component(\n",
    "        model_1 = finetune_model1_job.outputs.model_1,\n",
    "        model_2 = finetune_model2_job.outputs.model_2,\n",
    "        model_3 = finetune_model3_job.outputs.model_3,\n",
    "        test_data = train_job.outputs.test_data,\n",
    "        registered_model_name = pipeline_job_registered_model_name,\n",
    "    ) \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5501a68-7f61-468c-84a9-27ff42d2e38a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd21d2cc-a0c0-4847-80fe-a7489a316d4d",
   "metadata": {
    "gather": {
     "logged": 1728374791700
    }
   },
   "outputs": [],
   "source": [
    "registered_model_name = \"train_model\"\n",
    "\n",
    "\n",
    "# Let's instantiate the pipeline with the parameters of our choice\n",
    "pipeline = train_pipeline(pipeline_job_data_input=Input(type=\"uri_file\", path=data.path),\n",
    "                          pipeline_job_cv = 5,\n",
    "                          pipeline_job_n_trials = 50,\n",
    "                          pipeline_job_registered_model_name=registered_model_name,\n",
    "                        \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b29d29c8-0112-4ffb-8eae-bc69ec6fd1cf",
   "metadata": {
    "gather": {
     "logged": 1728374795107
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"Mobile_train_pipeline\",\n",
    ")\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.studio_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d7c7f-0928-4b5f-b7f8-08b4ebb001ff",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Create Name for end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a2ad608-38a6-4d81-86da-6de7da701a8f",
   "metadata": {
    "gather": {
     "logged": 1728374795318
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "online_endpoint_name = \"mobile-endpoint1-\" + str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53079bd8-fd5e-48d1-b459-f1aae099964c",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "If you encountered this error : 'HttpResponseError: (SubscriptionNotRegistered) Resource provider [N/A] isn't registered with Subscription [N/A].' \n",
    "\n",
    "Do the following\n",
    "\n",
    "Subscriptions > Azure subscription 1 > Resource providers > search for 'Microsoft.Cdn'  \n",
    "and  'Microsoft.PolicyInsights'register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15fab341-d019-4d13-9fd9-9faa4f4dedc6",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728374861232
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpint mobile-endpoint1-f51bfc69 provisioning state: Succeeded\n",
      "Endpint \"mobile-endpoint1-f51bfc69\" with provisioning state \"Succeeded\" is retrieved\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"mobile_defaults\",\n",
    "        \"model_type\": \"sklearn.RandomForestClassifier\",\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint_result = ml_client.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(\n",
    "    f\"Endpint {endpoint_result.name} provisioning state: {endpoint_result.provisioning_state}\"\n",
    ")\n",
    "\n",
    "\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print( f'Endpint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13094de-5e04-4a36-94fb-1ca6c4371665",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Select lastest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f1aa25a-73e4-4b96-9fdb-fa36fe29cb1b",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375211963
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "latest_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
    ")\n",
    "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f832ba36-0c76-4897-8e45-96a1e741c0d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/env.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/env.yaml\n",
    "name: custom_env_name\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8.0\n",
    "  - pip:\n",
    "      - azureml-mlflow==1.42.0\n",
    "      - azureml-sdk==1.38.0\n",
    "      - scikit-learn==0.24.2\n",
    "      - pandas>=1.1,<1.2\n",
    "      - numpy=1.21.2\n",
    "      - azureml-inference-server-http \n",
    "      - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-client\n",
    "      - git+https://github.com/microsoft/AzureML-Observability#subdirectory=aml-obs-collector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08d9e77c-ffd2-4853-ae83-2efc5ced1dd6",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375227807
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    name=custom_env_name,\n",
    "    conda_file=os.path.join(dependencies_dir, \"env.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    \n",
    ")\n",
    "environment = ml_client.environments.create_or_update(environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d13824-b377-44d4-b08b-a3facfd848ad",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Score Script for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "053167e8-a120-46e0-86b6-d7a21d3acaac",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375228092
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "scoring_dir = \"./components/scoring_script\"\n",
    "os.makedirs(scoring_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32c36c78-d42d-48e1-9361-36b214eb3bcb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./components/scoring_script/scoring_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scoring_dir}/scoring_script.py\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_dir = os.environ[\"AZUREML_MODEL_DIR\"]\n",
    "    model_path = os.path.join(model_dir, \"best_model/model.pkl\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        input_data = json.loads(data)  \n",
    "        columns = [\"ram_num\", \"battery_power_num\", \"px_width_num\", \"px_height_num\", \n",
    "                   \"mobile_wt_num\", \"int_memory_num\", \"n_cores_cat\"]\n",
    "                   \n",
    "        df = pd.DataFrame(input_data[\"input_data\"][\"data\"], columns=columns)\n",
    "        \n",
    "        prediction = model.predict(df)\n",
    "        \n",
    "        return prediction.tolist() \n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d02aa368-8892-4372-9512-824ed1ba5749",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375639338
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instance type Standard_DS1_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
      "Check: endpoint mobile-endpoint1-f51bfc69 exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................Deployment mobile provisioning state: Succeeded\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
    "\n",
    "code_config = CodeConfiguration(\n",
    "    code=\"./components/scoring_script\",  \n",
    "    scoring_script=\"scoring_script.py\")\n",
    "\n",
    "mobile_deployment = ManagedOnlineDeployment(\n",
    "    name=\"mobile\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model= model,\n",
    "    environment= 'azureml://registries/azureml/environments/sklearn-1.5/labels/latest',\n",
    "    code_configuration= code_config,\n",
    "    instance_type=\"Standard_DS1_v2\", #Standard_DS2_v2\n",
    "    instance_count=1\n",
    "   \n",
    ")\n",
    "\n",
    "mobile_deployment_results = ml_client.online_deployments.begin_create_or_update(\n",
    "    mobile_deployment\n",
    ").result()\n",
    "\n",
    "print(\n",
    "    f\"Deployment {mobile_deployment_results.name} provisioning state: {mobile_deployment_results.provisioning_state}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87e8d114-29d5-4ea0-bb6d-d632f6d8da93",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375671364
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint \"mobile-endpoint1-f51bfc69\" with provisioning state \"Succeeded\" is retrieved\n",
      "Deployment 'mobile' state: Succeeded\n",
      "Traffic for endpoint mobile-endpoint1-f51bfc69 is now routed to the 'mobile' deployment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
      "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the endpoint is in the \"Succeeded\" state before allocating traffic\n",
    "if endpoint.provisioning_state == \"Succeeded\":\n",
    "    print(f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved')\n",
    "\n",
    "    # Retrieve all deployments associated with this endpoint\n",
    "    deployments = ml_client.online_deployments.list(endpoint.name)\n",
    "    \n",
    "    # Find the specific deployment (e.g., \"mobile\") and check its state\n",
    "    deployment = next((d for d in deployments if d.name == \"mobile\"), None)\n",
    "\n",
    "    if deployment:\n",
    "        deployment_status = deployment.provisioning_state\n",
    "        print(f\"Deployment 'mobile' state: {deployment_status}\")\n",
    "\n",
    "        if deployment_status == \"Succeeded\":\n",
    "            # Assign 100% traffic to the 'mobile' deployment\n",
    "            endpoint.traffic = {\n",
    "                \"mobile\": 100  # 100% traffic to the 'mobile' deployment\n",
    "            }\n",
    "            # Apply the traffic allocation\n",
    "            ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "            print(f\"Traffic for endpoint {endpoint.name} is now routed to the 'mobile' deployment\")\n",
    "        else:\n",
    "            print(f\"Deployment 'mobile' is not in a valid state. Current state: {deployment_status}\")\n",
    "    else:\n",
    "        print(\"Deployment 'mobile' not found.\")\n",
    "else:\n",
    "    print(f\"Endpoint is not in a 'Succeeded' state. Current state: {endpoint.provisioning_state}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d084d-431d-4dd5-b2d7-c638a6cdda0b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a3ce99d-aca2-49d1-b273-aa767cda2d08",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375671600
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "deploy_dir = \"./deploy\"\n",
    "os.makedirs(deploy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4f70b8e-8d0f-45da-89d7-7a45d6074e84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./deploy/sample-request1234.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {deploy_dir}/sample-request1234.json\n",
    "\n",
    "{\n",
    "    \"input_data\": {\n",
    "        \"data\": [\n",
    "            [2549, 842, 756, 26.696685, 188, 7, 2],\n",
    "            [2863, 826, 786, 21.834586, 88, 58, 4],\n",
    "            [5000, 1000, 800, 24.34, 120, 58, 4]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7620b131-010e-4b53-b01a-210e53994713",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1728375672768
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 2, 3]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"./deploy/sample-request1234.json\",\n",
    "    deployment_name=\"mobile\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
